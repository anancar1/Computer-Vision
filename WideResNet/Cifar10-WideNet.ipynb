{
  "nbformat": 4,
  "nbformat_minor": 2,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "import numpy as np\r\n",
        "\r\n",
        "\r\n",
        "class MixupGenerator():\r\n",
        "    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\r\n",
        "        self.X_train = X_train\r\n",
        "        self.y_train = y_train\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.alpha = alpha\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.sample_num = len(X_train)\r\n",
        "        self.datagen = datagen\r\n",
        "\r\n",
        "    def __call__(self):\r\n",
        "        while True:\r\n",
        "            indexes = self.__get_exploration_order()\r\n",
        "            itr_num = int(len(indexes) // (self.batch_size * 2))\r\n",
        "\r\n",
        "            for i in range(itr_num):\r\n",
        "                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\r\n",
        "                X, y = self.__data_generation(batch_ids)\r\n",
        "\r\n",
        "                yield X, y\r\n",
        "\r\n",
        "    def __get_exploration_order(self):\r\n",
        "        indexes = np.arange(self.sample_num)\r\n",
        "\r\n",
        "        if self.shuffle:\r\n",
        "            np.random.shuffle(indexes)\r\n",
        "\r\n",
        "        return indexes\r\n",
        "\r\n",
        "    def __data_generation(self, batch_ids):\r\n",
        "        _, h, w, c = self.X_train.shape\r\n",
        "        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\r\n",
        "        X_l = l.reshape(self.batch_size, 1, 1, 1)\r\n",
        "        y_l = l.reshape(self.batch_size, 1)\r\n",
        "\r\n",
        "        X1 = self.X_train[batch_ids[:self.batch_size]]\r\n",
        "        X2 = self.X_train[batch_ids[self.batch_size:]]\r\n",
        "        X = X1 * X_l + X2 * (1 - X_l)\r\n",
        "\r\n",
        "        if self.datagen:\r\n",
        "            for i in range(self.batch_size):\r\n",
        "                X[i] = self.datagen.random_transform(X[i])\r\n",
        "                X[i] = self.datagen.standardize(X[i])\r\n",
        "\r\n",
        "        if isinstance(self.y_train, list):\r\n",
        "            y = []\r\n",
        "\r\n",
        "            for y_train_ in self.y_train:\r\n",
        "                y1 = y_train_[batch_ids[:self.batch_size]]\r\n",
        "                y2 = y_train_[batch_ids[self.batch_size:]]\r\n",
        "                y.append(y1 * y_l + y2 * (1 - y_l))\r\n",
        "        else:\r\n",
        "            y1 = self.y_train[batch_ids[:self.batch_size]]\r\n",
        "            y2 = self.y_train[batch_ids[self.batch_size:]]\r\n",
        "            y = y1 * y_l + y2 * (1 - y_l)\r\n",
        "\r\n",
        "        return X, y"
      ],
      "outputs": [],
      "metadata": {
        "id": "OlE-FFZH-dw8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "def get_random_eraser(p=0.5, s_l=0.02, s_h=0.4, r_1=0.3, r_2=1/0.3, v_l=0, v_h=255, pixel_level=False):\r\n",
        "    def eraser(input_img):\r\n",
        "        if input_img.ndim == 3:\r\n",
        "            img_h, img_w, img_c = input_img.shape\r\n",
        "        elif input_img.ndim == 2:\r\n",
        "            img_h, img_w = input_img.shape\r\n",
        "\r\n",
        "        p_1 = np.random.rand()\r\n",
        "\r\n",
        "        if p_1 > p:\r\n",
        "            return input_img\r\n",
        "\r\n",
        "        while True:\r\n",
        "            s = np.random.uniform(s_l, s_h) * img_h * img_w\r\n",
        "            r = np.random.uniform(r_1, r_2)\r\n",
        "            w = int(np.sqrt(s / r))\r\n",
        "            h = int(np.sqrt(s * r))\r\n",
        "            left = np.random.randint(0, img_w)\r\n",
        "            top = np.random.randint(0, img_h)\r\n",
        "\r\n",
        "            if left + w <= img_w and top + h <= img_h:\r\n",
        "                break\r\n",
        "\r\n",
        "        if pixel_level:\r\n",
        "            if input_img.ndim == 3:\r\n",
        "                c = np.random.uniform(v_l, v_h, (h, w, img_c))\r\n",
        "            if input_img.ndim == 2:\r\n",
        "                c = np.random.uniform(v_l, v_h, (h, w))\r\n",
        "        else:\r\n",
        "            c = np.random.uniform(v_l, v_h)\r\n",
        "\r\n",
        "        input_img[top:top + h, left:left + w] = c\r\n",
        "\r\n",
        "        return input_img\r\n",
        "\r\n",
        "    return eraser"
      ],
      "outputs": [],
      "metadata": {
        "id": "sbg8s6rR-lI1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [],
      "outputs": [],
      "metadata": {
        "id": "mC2clxdR_u6J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "source": [
        "from __future__ import print_function\r\n",
        "import keras\r\n",
        "from keras.datasets import cifar10\r\n",
        "from keras.models import Sequential,Model\r\n",
        "from keras.layers import Dense, Dropout, Activation, Flatten, Input,add,Add\r\n",
        "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D,AveragePooling2D\r\n",
        "from keras.layers.normalization import BatchNormalization \r\n",
        "from keras.layers import GaussianNoise as GN\r\n",
        "from keras.optimizers import SGD\r\n",
        "from keras.callbacks import LearningRateScheduler as LRS\r\n",
        "from keras.preprocessing.image import ImageDataGenerator\r\n",
        "\r\n",
        "batch_size = 128\r\n",
        "num_classes = 10\r\n",
        "epochs = 125\r\n",
        "\r\n",
        "\r\n",
        "#### LOAD AND TRANSFORM\r\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\r\n",
        "\r\n",
        "x_train = x_train.astype('float32')\r\n",
        "x_test = x_test.astype('float32')\r\n",
        "\r\n",
        "x_train /= 255\r\n",
        "x_test /= 255\r\n",
        "\r\n",
        "print(x_train.shape)\r\n",
        "print(x_test.shape)\r\n",
        "datagen = ImageDataGenerator(\r\n",
        "    width_shift_range=0.125,\r\n",
        "    height_shift_range=0.125,\r\n",
        "    horizontal_flip=True,\r\n",
        "    preprocessing_function=get_random_eraser(v_l=0, v_h=1))\r\n",
        "training_generator = MixupGenerator(x_train, y_train, batch_size=batch_size, alpha=0.7, datagen=datagen)()\r\n",
        "\r\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\r\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)\r\n",
        "\r\n",
        "def input_block(input, filtros):\r\n",
        "  x = Conv2D(16, (3, 3), padding='same')(input)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  return x\r\n",
        "\r\n",
        "def conv_block_wideresnet(input, filters=16, k=1, dropout=0.0, N=0):\r\n",
        "  x_res = Conv2D(filters * k, (1, 1), padding='same',strides=2)(input)\r\n",
        "\r\n",
        "  x = Conv2D(filters * k, (3, 3), padding='same',strides=2)(input)\r\n",
        "  x = BatchNormalization()(x)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  if dropout > 0.0:\r\n",
        "    x = Dropout(dropout)(x)\r\n",
        "\r\n",
        "  x = Conv2D(filters * k, (3, 3), padding='same')(x)\r\n",
        "  x_out = Add()([x, x_res])\r\n",
        "  for b in range(N-1):\r\n",
        "    x = BatchNormalization()(x_out)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Conv2D(filters * k, (3, 3), padding='same')(x)\r\n",
        "    if dropout > 0.0:\r\n",
        "      x = Dropout(dropout)(x)\r\n",
        "    x = BatchNormalization()(x)\r\n",
        "    x = Activation('relu')(x)\r\n",
        "    x = Conv2D(filters * k, (3, 3), padding='same')(x)\r\n",
        "    x_out = Add()([x,x_out])\r\n",
        "  \r\n",
        "  x = BatchNormalization()(x_out)\r\n",
        "  x = Activation('relu')(x)\r\n",
        "  return x\r\n",
        "\r\n",
        "\r\n",
        "# WIDE RESNET\r\n",
        "prof = 28\r\n",
        "N = (prof - 4)//6\r\n",
        "k = 10\r\n",
        "dropout = 0.0\r\n",
        "\r\n",
        "img_input = Input(shape= (x_train.shape[1:]))\r\n",
        "x = input_block(img_input,16)\r\n",
        "x = conv_block_wideresnet(x, 16 , k , dropout,N)\r\n",
        "x = conv_block_wideresnet(x, 32 , k , dropout,N)\r\n",
        "x = conv_block_wideresnet(x, 64 , k , dropout,N)\r\n",
        "dim1 = x.shape[1]\r\n",
        "x = AveragePooling2D(pool_size=dim1)(x)\r\n",
        "x = Flatten()(x)\r\n",
        "x = Dense(64, activation='relu')(x)\r\n",
        "out = Dense(num_classes, activation='softmax')(x)\r\n",
        "\r\n",
        "\r\n",
        "model = Model(img_input, out)\r\n",
        "\r\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "model.summary()\r\n",
        "\r\n",
        "def scheduler(epoch):\r\n",
        "    if epoch < 50:\r\n",
        "        return .1\r\n",
        "    elif epoch < 80:\r\n",
        "        return 0.01\r\n",
        "    else:\r\n",
        "        return 0.001\r\n",
        "\r\n",
        "set_lr = LRS(scheduler)\r\n",
        "\r\n",
        "history=model.fit(datagen.flow(x_train, y_train,batch_size=batch_size),\r\n",
        "                            steps_per_epoch=len(x_train) / batch_size, \r\n",
        "                            epochs=epochs,\r\n",
        "                            validation_data=(x_test, y_test),\r\n",
        "                            callbacks=[set_lr],\r\n",
        "                            verbose=1)\r\n",
        "\r\n",
        "\r\n",
        "## TEST\r\n",
        "scores = model.evaluate(x_test, y_test, verbose=1)\r\n",
        "print('Test loss:', scores[0])\r\n",
        "print('Test accuracy:', scores[1])\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "plt.plot(history.history['accuracy'])\r\n",
        "plt.plot(history.history['val_accuracy'])\r\n",
        "plt.title('Wide ResNet accuracy')\r\n",
        "plt.ylabel('Accuracy')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\r\n",
        "plt.show()\r\n",
        "\r\n",
        "plt.plot(history.history['loss'])\r\n",
        "plt.plot(history.history['val_loss'])\r\n",
        "plt.title('Wide ResNet loss')\r\n",
        "plt.ylabel('Loss')\r\n",
        "plt.xlabel('Epoch')\r\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\r\n",
        "plt.show()\r\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n",
            "(10000, 32, 32, 3)\n",
            "Model: \"model_7\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 32, 32, 3)]  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_308 (Conv2D)             (None, 32, 32, 16)   448         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_284 (BatchN (None, 32, 32, 16)   64          conv2d_308[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_284 (Activation)     (None, 32, 32, 16)   0           batch_normalization_284[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_310 (Conv2D)             (None, 16, 16, 160)  23200       activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_285 (BatchN (None, 16, 16, 160)  640         conv2d_310[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_285 (Activation)     (None, 16, 16, 160)  0           batch_normalization_285[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_311 (Conv2D)             (None, 16, 16, 160)  230560      activation_285[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_309 (Conv2D)             (None, 16, 16, 160)  2720        activation_284[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_138 (Add)                   (None, 16, 16, 160)  0           conv2d_311[0][0]                 \n",
            "                                                                 conv2d_309[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_286 (BatchN (None, 16, 16, 160)  640         add_138[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_286 (Activation)     (None, 16, 16, 160)  0           batch_normalization_286[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_312 (Conv2D)             (None, 16, 16, 160)  230560      activation_286[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_287 (BatchN (None, 16, 16, 160)  640         conv2d_312[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_287 (Activation)     (None, 16, 16, 160)  0           batch_normalization_287[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_313 (Conv2D)             (None, 16, 16, 160)  230560      activation_287[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_139 (Add)                   (None, 16, 16, 160)  0           conv2d_313[0][0]                 \n",
            "                                                                 add_138[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_288 (BatchN (None, 16, 16, 160)  640         add_139[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_288 (Activation)     (None, 16, 16, 160)  0           batch_normalization_288[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_314 (Conv2D)             (None, 16, 16, 160)  230560      activation_288[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_289 (BatchN (None, 16, 16, 160)  640         conv2d_314[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_289 (Activation)     (None, 16, 16, 160)  0           batch_normalization_289[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_315 (Conv2D)             (None, 16, 16, 160)  230560      activation_289[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_140 (Add)                   (None, 16, 16, 160)  0           conv2d_315[0][0]                 \n",
            "                                                                 add_139[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_290 (BatchN (None, 16, 16, 160)  640         add_140[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_290 (Activation)     (None, 16, 16, 160)  0           batch_normalization_290[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_316 (Conv2D)             (None, 16, 16, 160)  230560      activation_290[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_291 (BatchN (None, 16, 16, 160)  640         conv2d_316[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_291 (Activation)     (None, 16, 16, 160)  0           batch_normalization_291[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_317 (Conv2D)             (None, 16, 16, 160)  230560      activation_291[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_141 (Add)                   (None, 16, 16, 160)  0           conv2d_317[0][0]                 \n",
            "                                                                 add_140[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_292 (BatchN (None, 16, 16, 160)  640         add_141[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_292 (Activation)     (None, 16, 16, 160)  0           batch_normalization_292[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_319 (Conv2D)             (None, 8, 8, 320)    461120      activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_293 (BatchN (None, 8, 8, 320)    1280        conv2d_319[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_293 (Activation)     (None, 8, 8, 320)    0           batch_normalization_293[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_320 (Conv2D)             (None, 8, 8, 320)    921920      activation_293[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_318 (Conv2D)             (None, 8, 8, 320)    51520       activation_292[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_142 (Add)                   (None, 8, 8, 320)    0           conv2d_320[0][0]                 \n",
            "                                                                 conv2d_318[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_294 (BatchN (None, 8, 8, 320)    1280        add_142[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_294 (Activation)     (None, 8, 8, 320)    0           batch_normalization_294[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_321 (Conv2D)             (None, 8, 8, 320)    921920      activation_294[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_295 (BatchN (None, 8, 8, 320)    1280        conv2d_321[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_295 (Activation)     (None, 8, 8, 320)    0           batch_normalization_295[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_322 (Conv2D)             (None, 8, 8, 320)    921920      activation_295[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_143 (Add)                   (None, 8, 8, 320)    0           conv2d_322[0][0]                 \n",
            "                                                                 add_142[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_296 (BatchN (None, 8, 8, 320)    1280        add_143[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_296 (Activation)     (None, 8, 8, 320)    0           batch_normalization_296[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_323 (Conv2D)             (None, 8, 8, 320)    921920      activation_296[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_297 (BatchN (None, 8, 8, 320)    1280        conv2d_323[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_297 (Activation)     (None, 8, 8, 320)    0           batch_normalization_297[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_324 (Conv2D)             (None, 8, 8, 320)    921920      activation_297[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_144 (Add)                   (None, 8, 8, 320)    0           conv2d_324[0][0]                 \n",
            "                                                                 add_143[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_298 (BatchN (None, 8, 8, 320)    1280        add_144[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_298 (Activation)     (None, 8, 8, 320)    0           batch_normalization_298[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_325 (Conv2D)             (None, 8, 8, 320)    921920      activation_298[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_299 (BatchN (None, 8, 8, 320)    1280        conv2d_325[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_299 (Activation)     (None, 8, 8, 320)    0           batch_normalization_299[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_326 (Conv2D)             (None, 8, 8, 320)    921920      activation_299[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_145 (Add)                   (None, 8, 8, 320)    0           conv2d_326[0][0]                 \n",
            "                                                                 add_144[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_300 (BatchN (None, 8, 8, 320)    1280        add_145[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_300 (Activation)     (None, 8, 8, 320)    0           batch_normalization_300[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_328 (Conv2D)             (None, 4, 4, 640)    1843840     activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_301 (BatchN (None, 4, 4, 640)    2560        conv2d_328[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_301 (Activation)     (None, 4, 4, 640)    0           batch_normalization_301[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_329 (Conv2D)             (None, 4, 4, 640)    3687040     activation_301[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_327 (Conv2D)             (None, 4, 4, 640)    205440      activation_300[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_146 (Add)                   (None, 4, 4, 640)    0           conv2d_329[0][0]                 \n",
            "                                                                 conv2d_327[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_302 (BatchN (None, 4, 4, 640)    2560        add_146[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_302 (Activation)     (None, 4, 4, 640)    0           batch_normalization_302[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_330 (Conv2D)             (None, 4, 4, 640)    3687040     activation_302[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_303 (BatchN (None, 4, 4, 640)    2560        conv2d_330[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_303 (Activation)     (None, 4, 4, 640)    0           batch_normalization_303[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_331 (Conv2D)             (None, 4, 4, 640)    3687040     activation_303[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_147 (Add)                   (None, 4, 4, 640)    0           conv2d_331[0][0]                 \n",
            "                                                                 add_146[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_304 (BatchN (None, 4, 4, 640)    2560        add_147[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_304 (Activation)     (None, 4, 4, 640)    0           batch_normalization_304[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_332 (Conv2D)             (None, 4, 4, 640)    3687040     activation_304[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_305 (BatchN (None, 4, 4, 640)    2560        conv2d_332[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_305 (Activation)     (None, 4, 4, 640)    0           batch_normalization_305[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_333 (Conv2D)             (None, 4, 4, 640)    3687040     activation_305[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_148 (Add)                   (None, 4, 4, 640)    0           conv2d_333[0][0]                 \n",
            "                                                                 add_147[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_306 (BatchN (None, 4, 4, 640)    2560        add_148[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_306 (Activation)     (None, 4, 4, 640)    0           batch_normalization_306[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_334 (Conv2D)             (None, 4, 4, 640)    3687040     activation_306[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_307 (BatchN (None, 4, 4, 640)    2560        conv2d_334[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_307 (Activation)     (None, 4, 4, 640)    0           batch_normalization_307[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_335 (Conv2D)             (None, 4, 4, 640)    3687040     activation_307[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "add_149 (Add)                   (None, 4, 4, 640)    0           conv2d_335[0][0]                 \n",
            "                                                                 add_148[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_308 (BatchN (None, 4, 4, 640)    2560        add_149[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "activation_308 (Activation)     (None, 4, 4, 640)    0           batch_normalization_308[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 1, 1, 640)    0           activation_308[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_7 (Flatten)             (None, 640)          0           average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "dense_14 (Dense)                (None, 64)           41024       flatten_7[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_15 (Dense)                (None, 10)           650         dense_14[0][0]                   \n",
            "==================================================================================================\n",
            "Total params: 36,542,506\n",
            "Trainable params: 36,524,554\n",
            "Non-trainable params: 17,952\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/125\n",
            "390/390 [==============================] - 187s 465ms/step - loss: 2.9272 - accuracy: 0.1674 - val_loss: 2.0785 - val_accuracy: 0.2221\n",
            "Epoch 2/125\n",
            "390/390 [==============================] - 179s 459ms/step - loss: 1.8762 - accuracy: 0.2576 - val_loss: 1.7474 - val_accuracy: 0.3053\n",
            "Epoch 3/125\n",
            "390/390 [==============================] - 179s 457ms/step - loss: 1.7580 - accuracy: 0.3061 - val_loss: 2.2513 - val_accuracy: 0.2376\n",
            "Epoch 4/125\n",
            "390/390 [==============================] - 178s 457ms/step - loss: 1.6689 - accuracy: 0.3524 - val_loss: 1.7447 - val_accuracy: 0.3488\n",
            "Epoch 5/125\n",
            "390/390 [==============================] - 178s 456ms/step - loss: 1.6182 - accuracy: 0.3810 - val_loss: 9.6848 - val_accuracy: 0.1478\n",
            "Epoch 6/125\n",
            "390/390 [==============================] - 178s 455ms/step - loss: 1.5394 - accuracy: 0.4279 - val_loss: 1.8721 - val_accuracy: 0.3650\n",
            "Epoch 7/125\n",
            "390/390 [==============================] - 178s 455ms/step - loss: 1.4459 - accuracy: 0.4661 - val_loss: 2.1883 - val_accuracy: 0.3492\n",
            "Epoch 8/125\n",
            "390/390 [==============================] - 178s 456ms/step - loss: 1.3362 - accuracy: 0.5113 - val_loss: 1.5599 - val_accuracy: 0.4918\n",
            "Epoch 9/125\n",
            "390/390 [==============================] - 178s 455ms/step - loss: 1.2565 - accuracy: 0.5535 - val_loss: 2.9397 - val_accuracy: 0.4125\n",
            "Epoch 10/125\n",
            "390/390 [==============================] - 178s 455ms/step - loss: 1.1668 - accuracy: 0.5878 - val_loss: 1.3746 - val_accuracy: 0.5738\n",
            "Epoch 11/125\n",
            "390/390 [==============================] - 178s 454ms/step - loss: 1.0846 - accuracy: 0.6152 - val_loss: 1.7547 - val_accuracy: 0.4907\n",
            "Epoch 12/125\n",
            "390/390 [==============================] - 177s 454ms/step - loss: 1.0098 - accuracy: 0.6471 - val_loss: 1.1612 - val_accuracy: 0.6032\n",
            "Epoch 13/125\n",
            "390/390 [==============================] - 177s 454ms/step - loss: 0.9717 - accuracy: 0.6695 - val_loss: 0.9016 - val_accuracy: 0.7030\n",
            "Epoch 14/125\n",
            "390/390 [==============================] - 177s 454ms/step - loss: 0.9062 - accuracy: 0.6911 - val_loss: 0.8848 - val_accuracy: 0.7138\n",
            "Epoch 15/125\n",
            "390/390 [==============================] - 177s 453ms/step - loss: 0.8567 - accuracy: 0.7132 - val_loss: 2.0950 - val_accuracy: 0.4805\n",
            "Epoch 16/125\n",
            "390/390 [==============================] - 177s 454ms/step - loss: 0.8443 - accuracy: 0.7194 - val_loss: 1.3221 - val_accuracy: 0.6376\n",
            "Epoch 17/125\n",
            "390/390 [==============================] - 177s 453ms/step - loss: 0.7886 - accuracy: 0.7385 - val_loss: 1.2313 - val_accuracy: 0.6370\n",
            "Epoch 18/125\n",
            "390/390 [==============================] - 177s 452ms/step - loss: 0.7649 - accuracy: 0.7549 - val_loss: 3.6600 - val_accuracy: 0.4320\n",
            "Epoch 19/125\n",
            "390/390 [==============================] - 177s 452ms/step - loss: 0.7371 - accuracy: 0.7635 - val_loss: 0.9683 - val_accuracy: 0.7086\n",
            "Epoch 20/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.6971 - accuracy: 0.7735 - val_loss: 0.6892 - val_accuracy: 0.7876\n",
            "Epoch 21/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.6663 - accuracy: 0.7879 - val_loss: 1.0294 - val_accuracy: 0.7100\n",
            "Epoch 22/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.6414 - accuracy: 0.7945 - val_loss: 0.7962 - val_accuracy: 0.7641\n",
            "Epoch 23/125\n",
            "390/390 [==============================] - 177s 452ms/step - loss: 0.6123 - accuracy: 0.8040 - val_loss: 0.7052 - val_accuracy: 0.7935\n",
            "Epoch 24/125\n",
            "390/390 [==============================] - 177s 452ms/step - loss: 0.5993 - accuracy: 0.8075 - val_loss: 1.0204 - val_accuracy: 0.7198\n",
            "Epoch 25/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.5768 - accuracy: 0.8200 - val_loss: 0.7239 - val_accuracy: 0.7864\n",
            "Epoch 26/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.5490 - accuracy: 0.8273 - val_loss: 0.8164 - val_accuracy: 0.7781\n",
            "Epoch 27/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.5444 - accuracy: 0.8266 - val_loss: 0.6359 - val_accuracy: 0.8118\n",
            "Epoch 28/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.5369 - accuracy: 0.8314 - val_loss: 0.7031 - val_accuracy: 0.8038\n",
            "Epoch 29/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.5113 - accuracy: 0.8384 - val_loss: 0.5655 - val_accuracy: 0.8344\n",
            "Epoch 30/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.4947 - accuracy: 0.8444 - val_loss: 0.5641 - val_accuracy: 0.8314\n",
            "Epoch 31/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.4702 - accuracy: 0.8513 - val_loss: 0.6820 - val_accuracy: 0.7965\n",
            "Epoch 32/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.4664 - accuracy: 0.8526 - val_loss: 0.6924 - val_accuracy: 0.8092\n",
            "Epoch 33/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.4542 - accuracy: 0.8549 - val_loss: 0.8146 - val_accuracy: 0.7732\n",
            "Epoch 34/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.4353 - accuracy: 0.8610 - val_loss: 0.6177 - val_accuracy: 0.8213\n",
            "Epoch 35/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.4395 - accuracy: 0.8630 - val_loss: 0.7493 - val_accuracy: 0.8072\n",
            "Epoch 36/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.4142 - accuracy: 0.8678 - val_loss: 0.5508 - val_accuracy: 0.8431\n",
            "Epoch 37/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.4176 - accuracy: 0.8690 - val_loss: 0.6108 - val_accuracy: 0.8354\n",
            "Epoch 38/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3941 - accuracy: 0.8736 - val_loss: 0.6533 - val_accuracy: 0.8169\n",
            "Epoch 39/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.3805 - accuracy: 0.8789 - val_loss: 0.5677 - val_accuracy: 0.8380\n",
            "Epoch 40/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3937 - accuracy: 0.8784 - val_loss: 0.4643 - val_accuracy: 0.8668\n",
            "Epoch 41/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3598 - accuracy: 0.8847 - val_loss: 0.5825 - val_accuracy: 0.8401\n",
            "Epoch 42/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3513 - accuracy: 0.8900 - val_loss: 0.6196 - val_accuracy: 0.8318\n",
            "Epoch 43/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3561 - accuracy: 0.8878 - val_loss: 0.5093 - val_accuracy: 0.8619\n",
            "Epoch 44/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3490 - accuracy: 0.8902 - val_loss: 0.5276 - val_accuracy: 0.8603\n",
            "Epoch 45/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3436 - accuracy: 0.8923 - val_loss: 0.7664 - val_accuracy: 0.8195\n",
            "Epoch 46/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3375 - accuracy: 0.8923 - val_loss: 0.5211 - val_accuracy: 0.8635\n",
            "Epoch 47/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3301 - accuracy: 0.8968 - val_loss: 0.5624 - val_accuracy: 0.8584\n",
            "Epoch 48/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3179 - accuracy: 0.9020 - val_loss: 0.5742 - val_accuracy: 0.8624\n",
            "Epoch 49/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.3139 - accuracy: 0.9015 - val_loss: 0.5912 - val_accuracy: 0.8561\n",
            "Epoch 50/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.3234 - accuracy: 0.9000 - val_loss: 0.4435 - val_accuracy: 0.8790\n",
            "Epoch 51/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.2424 - accuracy: 0.9234 - val_loss: 0.3384 - val_accuracy: 0.9040\n",
            "Epoch 52/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.2014 - accuracy: 0.9355 - val_loss: 0.3276 - val_accuracy: 0.9074\n",
            "Epoch 53/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.2003 - accuracy: 0.9359 - val_loss: 0.3249 - val_accuracy: 0.9079\n",
            "Epoch 54/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1904 - accuracy: 0.9398 - val_loss: 0.3330 - val_accuracy: 0.9084\n",
            "Epoch 55/125\n",
            "390/390 [==============================] - 176s 452ms/step - loss: 0.1770 - accuracy: 0.9440 - val_loss: 0.3336 - val_accuracy: 0.9092\n",
            "Epoch 56/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1807 - accuracy: 0.9420 - val_loss: 0.3178 - val_accuracy: 0.9137\n",
            "Epoch 57/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1730 - accuracy: 0.9457 - val_loss: 0.3320 - val_accuracy: 0.9086\n",
            "Epoch 58/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1671 - accuracy: 0.9472 - val_loss: 0.3295 - val_accuracy: 0.9104\n",
            "Epoch 59/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1661 - accuracy: 0.9466 - val_loss: 0.3226 - val_accuracy: 0.9124\n",
            "Epoch 60/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1593 - accuracy: 0.9487 - val_loss: 0.3328 - val_accuracy: 0.9125\n",
            "Epoch 61/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1608 - accuracy: 0.9479 - val_loss: 0.3174 - val_accuracy: 0.9159\n",
            "Epoch 62/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1538 - accuracy: 0.9493 - val_loss: 0.3195 - val_accuracy: 0.9167\n",
            "Epoch 63/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1565 - accuracy: 0.9507 - val_loss: 0.3206 - val_accuracy: 0.9160\n",
            "Epoch 64/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1511 - accuracy: 0.9522 - val_loss: 0.3208 - val_accuracy: 0.9154\n",
            "Epoch 65/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1505 - accuracy: 0.9504 - val_loss: 0.3217 - val_accuracy: 0.9163\n",
            "Epoch 66/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1479 - accuracy: 0.9524 - val_loss: 0.3179 - val_accuracy: 0.9177\n",
            "Epoch 67/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1406 - accuracy: 0.9552 - val_loss: 0.3467 - val_accuracy: 0.9104\n",
            "Epoch 68/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1427 - accuracy: 0.9560 - val_loss: 0.3349 - val_accuracy: 0.9109\n",
            "Epoch 69/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1409 - accuracy: 0.9556 - val_loss: 0.3226 - val_accuracy: 0.9160\n",
            "Epoch 70/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1411 - accuracy: 0.9546 - val_loss: 0.3413 - val_accuracy: 0.9118\n",
            "Epoch 71/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1382 - accuracy: 0.9549 - val_loss: 0.3266 - val_accuracy: 0.9158\n",
            "Epoch 72/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1363 - accuracy: 0.9566 - val_loss: 0.3559 - val_accuracy: 0.9116\n",
            "Epoch 73/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1309 - accuracy: 0.9569 - val_loss: 0.3338 - val_accuracy: 0.9150\n",
            "Epoch 74/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1355 - accuracy: 0.9567 - val_loss: 0.3191 - val_accuracy: 0.9198\n",
            "Epoch 75/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1328 - accuracy: 0.9570 - val_loss: 0.3316 - val_accuracy: 0.9195\n",
            "Epoch 76/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1300 - accuracy: 0.9578 - val_loss: 0.3284 - val_accuracy: 0.9179\n",
            "Epoch 77/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1274 - accuracy: 0.9589 - val_loss: 0.3315 - val_accuracy: 0.9168\n",
            "Epoch 78/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1267 - accuracy: 0.9594 - val_loss: 0.3272 - val_accuracy: 0.9181\n",
            "Epoch 79/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1285 - accuracy: 0.9575 - val_loss: 0.3327 - val_accuracy: 0.9180\n",
            "Epoch 80/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1247 - accuracy: 0.9594 - val_loss: 0.3315 - val_accuracy: 0.9213\n",
            "Epoch 81/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1170 - accuracy: 0.9625 - val_loss: 0.3178 - val_accuracy: 0.9213\n",
            "Epoch 82/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1154 - accuracy: 0.9625 - val_loss: 0.3172 - val_accuracy: 0.9213\n",
            "Epoch 83/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1173 - accuracy: 0.9628 - val_loss: 0.3174 - val_accuracy: 0.9221\n",
            "Epoch 84/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1138 - accuracy: 0.9629 - val_loss: 0.3190 - val_accuracy: 0.9233\n",
            "Epoch 85/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1151 - accuracy: 0.9625 - val_loss: 0.3167 - val_accuracy: 0.9220\n",
            "Epoch 86/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1157 - accuracy: 0.9632 - val_loss: 0.3161 - val_accuracy: 0.9225\n",
            "Epoch 87/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1147 - accuracy: 0.9634 - val_loss: 0.3180 - val_accuracy: 0.9217\n",
            "Epoch 88/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1126 - accuracy: 0.9630 - val_loss: 0.3166 - val_accuracy: 0.9216\n",
            "Epoch 89/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1146 - accuracy: 0.9638 - val_loss: 0.3159 - val_accuracy: 0.9229\n",
            "Epoch 90/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1095 - accuracy: 0.9640 - val_loss: 0.3180 - val_accuracy: 0.9220\n",
            "Epoch 91/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1093 - accuracy: 0.9645 - val_loss: 0.3174 - val_accuracy: 0.9230\n",
            "Epoch 92/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1176 - accuracy: 0.9618 - val_loss: 0.3163 - val_accuracy: 0.9220\n",
            "Epoch 93/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1093 - accuracy: 0.9641 - val_loss: 0.3194 - val_accuracy: 0.9227\n",
            "Epoch 94/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1078 - accuracy: 0.9663 - val_loss: 0.3187 - val_accuracy: 0.9219\n",
            "Epoch 95/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1186 - accuracy: 0.9612 - val_loss: 0.3154 - val_accuracy: 0.9228\n",
            "Epoch 96/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1101 - accuracy: 0.9659 - val_loss: 0.3141 - val_accuracy: 0.9227\n",
            "Epoch 97/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1089 - accuracy: 0.9652 - val_loss: 0.3146 - val_accuracy: 0.9228\n",
            "Epoch 98/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1130 - accuracy: 0.9633 - val_loss: 0.3154 - val_accuracy: 0.9237\n",
            "Epoch 99/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1094 - accuracy: 0.9652 - val_loss: 0.3193 - val_accuracy: 0.9229\n",
            "Epoch 100/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1070 - accuracy: 0.9664 - val_loss: 0.3155 - val_accuracy: 0.9225\n",
            "Epoch 101/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1126 - accuracy: 0.9641 - val_loss: 0.3176 - val_accuracy: 0.9232\n",
            "Epoch 102/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1081 - accuracy: 0.9643 - val_loss: 0.3171 - val_accuracy: 0.9224\n",
            "Epoch 103/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1102 - accuracy: 0.9648 - val_loss: 0.3146 - val_accuracy: 0.9240\n",
            "Epoch 104/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1113 - accuracy: 0.9653 - val_loss: 0.3131 - val_accuracy: 0.9237\n",
            "Epoch 105/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1084 - accuracy: 0.9655 - val_loss: 0.3156 - val_accuracy: 0.9238\n",
            "Epoch 106/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1128 - accuracy: 0.9645 - val_loss: 0.3156 - val_accuracy: 0.9231\n",
            "Epoch 107/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1099 - accuracy: 0.9642 - val_loss: 0.3161 - val_accuracy: 0.9228\n",
            "Epoch 108/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1017 - accuracy: 0.9663 - val_loss: 0.3209 - val_accuracy: 0.9227\n",
            "Epoch 109/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1071 - accuracy: 0.9658 - val_loss: 0.3174 - val_accuracy: 0.9239\n",
            "Epoch 110/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1126 - accuracy: 0.9640 - val_loss: 0.3171 - val_accuracy: 0.9232\n",
            "Epoch 111/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1094 - accuracy: 0.9648 - val_loss: 0.3181 - val_accuracy: 0.9212\n",
            "Epoch 112/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1136 - accuracy: 0.9638 - val_loss: 0.3185 - val_accuracy: 0.9231\n",
            "Epoch 113/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1072 - accuracy: 0.9655 - val_loss: 0.3189 - val_accuracy: 0.9229\n",
            "Epoch 114/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1036 - accuracy: 0.9672 - val_loss: 0.3187 - val_accuracy: 0.9226\n",
            "Epoch 115/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1140 - accuracy: 0.9629 - val_loss: 0.3186 - val_accuracy: 0.9218\n",
            "Epoch 116/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1089 - accuracy: 0.9655 - val_loss: 0.3198 - val_accuracy: 0.9231\n",
            "Epoch 117/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1104 - accuracy: 0.9643 - val_loss: 0.3181 - val_accuracy: 0.9244\n",
            "Epoch 118/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1090 - accuracy: 0.9633 - val_loss: 0.3203 - val_accuracy: 0.9221\n",
            "Epoch 119/125\n",
            "390/390 [==============================] - 176s 450ms/step - loss: 0.1049 - accuracy: 0.9667 - val_loss: 0.3194 - val_accuracy: 0.9229\n",
            "Epoch 120/125\n",
            "390/390 [==============================] - 176s 451ms/step - loss: 0.1074 - accuracy: 0.9648 - val_loss: 0.3190 - val_accuracy: 0.9232\n",
            "Epoch 121/125\n",
            "390/390 [==============================] - 175s 449ms/step - loss: 0.1005 - accuracy: 0.9667 - val_loss: 0.3228 - val_accuracy: 0.9218\n",
            "Epoch 122/125\n",
            "390/390 [==============================] - 175s 449ms/step - loss: 0.1096 - accuracy: 0.9647 - val_loss: 0.3193 - val_accuracy: 0.9225\n",
            "Epoch 123/125\n",
            "390/390 [==============================] - 175s 448ms/step - loss: 0.1026 - accuracy: 0.9673 - val_loss: 0.3213 - val_accuracy: 0.9225\n",
            "Epoch 124/125\n",
            "390/390 [==============================] - 175s 449ms/step - loss: 0.1057 - accuracy: 0.9661 - val_loss: 0.3212 - val_accuracy: 0.9218\n",
            "Epoch 125/125\n",
            "390/390 [==============================] - 175s 448ms/step - loss: 0.1102 - accuracy: 0.9661 - val_loss: 0.3210 - val_accuracy: 0.9225\n",
            "313/313 [==============================] - 16s 52ms/step - loss: 0.3210 - accuracy: 0.9225\n",
            "Test loss: 0.32102417945861816\n",
            "Test accuracy: 0.9225000143051147\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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"
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Zl4_STNX-pkh",
        "outputId": "9c91773c-1c03-4c9a-b775-68c741945e3a"
      }
    }
  ]
}